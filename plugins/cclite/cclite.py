import plugins
import requests
import json
from bridge.context import ContextType
from bridge.reply import Reply, ReplyType
from channel.chat_message import ChatMessage
from plugins import *
from common.log import logger
import os
from .lib.model_factory import ModelGenerator
from .lib.unifiedmodel import UnifiedChatbot


@plugins.register(
    name="cclite",
    desc="A plugin that supports multi-function_call",
    version="0.1.0",
    author="cc",
    desire_priority=66
)
class CCLite(Plugin):
    def __init__(self):
        super().__init__()
        self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context
        try:
                self.c_model = ModelGenerator()
                # åˆ›å»º UnifiedChatbot å®ä¾‹
                self.c_modelpro = UnifiedChatbot()
                logger.info("[cclite] inited")
        except Exception as e:
            logger.error(f"[cclite] init error: {e}")

    
    def on_handle_context(self, e_context: EventContext):
        context = e_context['context']
        msg: ChatMessage = context['msg']
        # user_id = msg.from_user_id
        isgroup = e_context["context"].get("isgroup")
        user_id = msg.actual_user_id if isgroup else msg.from_user_id
        # è¿‡æ»¤ä¸éœ€è¦å¤„ç†çš„å†…å®¹ç±»å‹
        if context.type not in [ContextType.TEXT, ContextType.IMAGE, ContextType.IMAGE_CREATE, ContextType.FILE, ContextType.SHARING]:
            return

        if context.type == ContextType.TEXT:

            content_lower = context.content.lower()
            if "cc openai" in content_lower:
                self.c_model.set_ai_model("OpenAI")
                self.c_modelpro.set_ai_model("OpenAI")
                _set_reply_text("å·²åˆ‡æ¢åˆ°OpenAIæ¨¡å‹ã€‚", e_context, level=ReplyType.TEXT)
                return
            elif "cc gemini" in content_lower:
                self.c_model.set_ai_model("Gemini")
                self.c_modelpro.set_ai_model("Gemini")
                _set_reply_text("å·²åˆ‡æ¢åˆ°Geminiæ¨¡å‹ã€‚", e_context, level=ReplyType.TEXT)
                return
            elif "cc qwen" in content_lower:
                self.c_model.set_ai_model("Qwen")
                self.c_modelpro.set_ai_model("Qwen")
                _set_reply_text("å·²åˆ‡æ¢åˆ°Qwenæ¨¡å‹ã€‚", e_context, level=ReplyType.TEXT)
                return
            elif "cmodel" in content_lower:
                response = self.c_model.get_current_model()
                _set_reply_text(response, e_context, level=ReplyType.TEXT)
                return

            user_input = context.content
            response = self.c_modelpro.get_model_reply(user_input, user_id)
            _set_reply_text(response, e_context, level=ReplyType.TEXT)     
            return

    def get_help_text(self, verbose=False, **kwargs):
        # åˆå§‹åŒ–å¸®åŠ©æ–‡æœ¬ï¼Œæ’ä»¶çš„åŸºç¡€æè¿°
        help_text = "\nğŸ¤– åŸºäºå¾®ä¿¡çš„å¤šåŠŸèƒ½èŠå¤©æœºå™¨äººï¼Œæä¾›æ–°é—»ã€å¤©æ°”ã€ç«è½¦ç¥¨ä¿¡æ¯ã€å¨±ä¹å†…å®¹ç­‰å®ç”¨æœåŠ¡ã€‚\n"
        
        # å¦‚æœä¸éœ€è¦è¯¦ç»†è¯´æ˜ï¼Œåˆ™ç›´æ¥è¿”å›å¸®åŠ©æ–‡æœ¬
        if not verbose:
            return help_text
        
        # æ·»åŠ è¯¦ç»†çš„ä½¿ç”¨æ–¹æ³•åˆ°å¸®åŠ©æ–‡æœ¬ä¸­
        help_text += """
            å›½äº§å¤§æ¨¡å‹
        """    
        # è¿”å›å¸®åŠ©æ–‡æœ¬
        return help_text

def _send_info(e_context: EventContext, content: str):
    reply = Reply(ReplyType.TEXT, content)
    channel = e_context["channel"]
    channel.send(reply, e_context["context"])

def _set_reply_text(content: str, e_context: EventContext, level: ReplyType = ReplyType.ERROR):
    reply = Reply(level, content)
    e_context["reply"] = reply
    e_context.action = EventAction.BREAK_PASS

def remove_markdown(text):
    # æ›¿æ¢Markdownçš„ç²—ä½“æ ‡è®°
    text = text.replace("**", "")
    # æ›¿æ¢Markdownçš„æ ‡é¢˜æ ‡è®°
    text = text.replace("### ", "").replace("## ", "").replace("# ", "")
    return text




